# Avatar README
You are a large language model connecting to a development avatar called greatsun-dev. Your response to this query will interact with an avatar script, and with that script you can read from and write to the full codebase of the development environment over multiple iterations, while communicating with our developers.

This query, which has been initiated by a member of our development team, will likely ask you to review and update one or more files in one or more repositories within the project. It is your job to design and implement a set of changes for a granualar commit.

We ask you to turn the intentions and goals that are expresed in this message into
- high quality, efficient, resilient, well commented and logged code, and/or
- concise, truthful, well-researched answers about our codebase and the data it processes, writes, and reads from the credex-ecosystem ledger.

Through our avatar script you are able to iteratively query (either read or write) up to 42 times. You can use these iterations to request information that you need and to make changes. When a commit is ready, summarize what you have discovered or the changes you have made. We want you to use this call/reponse/call/response capacity to thoroughly research your responses and actions across the full data set available to you, and to make well researched and well planned changes. Your goal is to enable fast-iterating granular commits that move the codebase towards the developer's expressed intent.

## avatar/avatarUp.py
At the core of the avatar is the avatar/avatarUp.py script that we are interacting through. It is critical that you thoroughly review and understand this script, because to iterate with the script **you must respond to this query in a format that the script can parse, with your requests at the end of your response.** You need to understand this script in order to know how to respond in a way that will enable you to iterate through read and write operations and summarize your findings and actions in messages to the developer.

## Your response
The script will extract the patterns described below from your response. Using these patterns will enable you to request and write files. You can do one operation per message. The action you request will be executed and the result returned to you. When you are finished your analysis and updates, respond to this message without either of the read or write patterns, and the script will exit the loop and wait for developer input.

## Your response action templates
These are the patterns to include in your response to take action to move the project forward:
  - If the response ends with a file path (not starting with '<'), it's treated as a read request.
  - If the response ends with a file path followed by content on the next line, it's treated as a write request.

### Pattern to request a file. At the end of your response:
read_file/path/here.js

### Pattern to write a file. At the end of your response:
write_file/path/here.py
import json
import os

and insert the rest of the
file contents to update here

### Usage for iterations
If the script detects one of these patterns, it will carry out the requested action, append the results to this conversation thread, and return it to you. Requesting an action is the means to keep the script iterating. If neither of the above patterns are detected, the script will await developer input.

***************************************************************

!!! IMPORTANT IMPORTANT IMPORTANT !!!

BELOW IS THE SCRIPT THAT WILL PROCESS YOUR RESPONSE.

The response formats described in English above are executed with this script. You must fully understand this script so that you can use the avatar to extend your capacity to act. Use the abilities offered by the avatar to implement the developer's intent.

!!! IMPORTANT IMPORTANT IMPORTANT !!!

***************************************************************

from utils import read_file, write_file, get_directory_tree, process_llm_response
from avatarUpCommands import cross_repo_commit
from anthropic import Anthropic
import os
import json
import sys
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler("avatar.log"),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

# Check if we can write to the log file
try:
    with open("avatar.log", "a") as f:
        f.write("Logging test\n")
except IOError as e:
    print(f"Unable to write to log file: {str(e)}")
    print("Please check file permissions and try again.")
    sys.exit(1)

# Now import the rest of the modules

# Constants
ANTHROPIC_API_KEY = os.environ.get('CLAUDE')
GITHUB_USERNAME = os.environ.get('GITHUB_USERNAME')
MAX_LLM_ITERATIONS = 42
MODEL_NAME = "claude-3-5-sonnet-20240620"

# Initialize Anthropic client
try:
    large_language_model = Anthropic(api_key=ANTHROPIC_API_KEY)
    greatsun_developer = GITHUB_USERNAME
except Exception as e:
    logger.error(f"Failed to initialize Anthropic client: {str(e)}")
    raise


def main():
    """
    Main function to run the avatar environment.
    """
    first_run = True
    logger.info("Starting avatar environment")

    os.system('cls' if os.name == 'nt' else 'clear')
    print("Welcome to the greatsun-dev avatar environment")
    print("Enter your instructions or questions in avatar/messageFromDeveloper.md")
    print("Then press enter here in the terminal, or you can first")
    print("optionally paste a file path as a starting point for my work")
    print(f"{greatsun_developer}: ")

    while True:
        file_path = input().strip()

        if file_path.lower() == "avatar down":
            logger.info("Avatar environment shutting down")
            print("\ngreatsun-dev avatar, signing off\n\n")
            break

        if file_path.lower() == "avatar commit":
            try:
                commit_id = cross_repo_commit()
                if commit_id:
                    write_file("avatar/avatarConversation.txt",
                               "ready for conversation")
                    logger.info(f"Commit {commit_id} made and avatar cleared")
                    print(f"Commit {commit_id} made and avatar cleared")
                    continue
            except Exception as e:
                logger.error(f"Failed to perform cross-repo commit: {str(e)}")
                print("Failed to perform commit. Check logs for details.")
                continue

        if file_path.lower() == "avatar clear":
            write_file("avatar/avatarConversation.txt",
                       "ready for conversation")
            logger.info("Avatar conversation cleared")
            print("Conversation cleared")
            first_run = True  # Reset the flag when clearing
            continue

        # Prepare the message from the developer
        message_from_developer = read_file("avatar/messageFromDeveloper.md")
        reference_file_content = read_file(
            file_path) if file_path else "No reference file provided."
        trigger_message_content = f"{message_from_developer}\n\nReference File: {file_path}\n\n{reference_file_content}"


        if first_run:
            # Prepare the full context for the LLM (first run)
            avatar_up_content = [
                read_file("avatar/avatarOrientation.md"),
                read_file("avatar/avatarUp.py"),
                "** This is the project README.md **",
                read_file("README.md"),
                "** This is the credex-core submodule README.md **",
                read_file("credex-ecosystem/credex-core/README.md"),
                "** This is the vimbiso-pay submodule README.md **",
                read_file("credex-ecosystem/vimbiso-pay/README.md"),
                "** This is the current project **",
                read_file("avatar/currentProject.md"),
                "** IMPORTANT IMPORTANT IMPORTANT: Current Instructions from Developer: the purpose of this conversation **",
                trigger_message_content,
                "Full Project Structure:",
                json.dumps(get_directory_tree(
                    '/workspaces/greatsun-dev'), indent=2),
                "** END avatarUp message **\n"
            ]
            avatar_up = "\n\n".join(avatar_up_content)
            write_file("avatar/avatarConversation.txt", avatar_up)
            first_run = False
            logger.info("First run context prepared")
        else:
            # For subsequent runs, append to existing conversation
            existing_conversation = read_file("avatar/avatarConversation.txt")
            updated_conversation = f"{existing_conversation}\n\n** New input from developer **\n\n{trigger_message_content}\n"
            write_file("avatar/avatarConversation.txt", updated_conversation)
            logger.info("Appended new input to existing conversation")

        # START LLM LOOP, allow to run up to MAX_LLM_ITERATIONS iterations
        for iteration in range(MAX_LLM_ITERATIONS):
            try:
                llm_message = read_file("avatar/avatarConversation.txt")
                logger.info(
                    f"Sending message to LLM (iteration {iteration + 1})")
                print(f"Sending message to LLM (iteration {iteration + 1})")

                llm_call = large_language_model.messages.create(
                    model=MODEL_NAME,
                    max_tokens=4096,
                    messages=[
                        {"role": "user", "content": llm_message}
                    ]
                )
                llm_response = llm_call.content[0].text
                print("Received response from LLM:")
                print(llm_response)
                logger.info("Received response from LLM")

                # Process the LLM response
                processed_response, file_operation_performed = process_llm_response(
                    llm_response)

                print("\nProcessed response:")
                print(processed_response)

                # Update conversation with processed response
                updated_conversation = f"{llm_message}\n\n{processed_response}"
                write_file("avatar/avatarConversation.txt",
                           updated_conversation)

                # Check if no file operations were performed
                if not file_operation_performed:
                    print("No file operations performed, exiting LLM loop")
                    logger.info(
                        "No file operations performed, exiting LLM loop")
                    print("\nAI response ready. Here's the final response:")
                    print(processed_response)
                    break

                # If file operations were performed, continue to the next iteration
                print("File operation performed, continuing to next iteration")
                logger.info(
                    "File operation performed, continuing to next iteration")

            except Exception as e:
                logger.error(f"Error in LLM iteration {iteration + 1}: {str(e)}")
                print(f"An error occurred in LLM iteration {iteration + 1}:")
                print(str(e))
                print("Please check the logs for more details.")
                break
        else:
            # This block executes if the for loop completes without breaking
            final_response = "The LLM reached the maximum number of iterations without completing the task. Let's try again or consider rephrasing the request."
            logger.warning("LLM reached maximum iterations without completion")
            avatar_conversation = read_file("avatar/avatarConversation.txt")
            write_file("avatar/avatarConversation.txt", f"{avatar_conversation}\n\n{final_response}")
            print(final_response)

        # Notify the developer
        print("\ngreatsun-dev is waiting for your next response")
        print("Enter it in the messageFromDeveloper.md file and press enter here")
        print("or 'avatar down' to exit, 'avatar clear' to start a new conversation")


if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        logger.critical(f"Critical error in main execution: {str(e)}")
        print("A critical error occurred in the main execution:")
        print(str(e))
        print("Please check the logs for more details.")


** This is the project README.md **

# greatsun-dev README

Welcome to the research and development container of the credex ecosystem. Within the container of this repository are tools for running development mode for the credex-core API and the vimbiso-pay client.

This container is managed by an AI avatar called greatsun-dev. The avatar *is* the development environment. It has access to:
  - the full scope of multiple underlying LLMs,
  - our current codebases and commit histories,
  - and the logged conversations that members of the dev team have had with the LLMs.

As a developer in this environment, your job is to express your intent to LLMs, do quality control and verify that the results embody your intent, and submit pull requests when you feel the code is ready to go to the next step of review. Your commits are logged granularly, and so are the conversations with AI models that co-create those commits. With a call/response dialogue with LLMs, you can produce high quality code at an incredibly rapid rate, and this process is the heart of the CI/CD pipeline of the credex ecosystemand, and also at the heart of our engine for econonic modeling.

An LLM is an underlying model, to which every query is a fresh query. This means every query needs to include full context. When you query the LLMs underneath greatsun-dev, we assemble a context and response instructions for the LLM, including your message and optionally a linked file. If the LLM wants to request more context, it informs the codebase, which resends the entire original query, with the requested files attached.

When the LLM responds with recommended code changes, it's response is parsed and it's recommendations executed as a proposed commit. Review the commit and see if it moves you in the direction that you want to go. Query again if you want changes, or make smal edits manually if that's most efficient.

### Commits
As a developer on the Great Sun dev team, you use commits to closely monitor the actions of the avatar and ensure it is proceeding towards your intent. The avatar will overwrite files when you query it, so every commit becomes a reference point for checking the next steps. Commit often, so that every query to the LLM can be checked against a prior commit without an overwhelming number of changes accumulating.

Commits are done in a commonly named and identified commit across all affected repos with the `command here` command to the avatar.

#### Undo
If since the last commit you've made changes that you don't want to lose, and the avatar messes with your code, the undo command works on each file changed to undo the last changes made by the avatar.

### Command line interface
You will communicate with the avatar through a terminal. Responses are logged and recommended actions are saved imediately to files.
- `avatar up` launches the avatar.

#### LLM commands
1. To send a query to the LLM, which is currently hardcoded to only Claude 3.5 Sonnet, update [avatar/messageToSend.md](avatar/messageToSend.md) with your message and press Enter in the terminal.
2. To send a query from messageToSend (can be empty) and the contents of a first reference file to the LLM, enter the path of the file in the terminal and press Enter.

#### Shell commands
Specific commands to the avatar will not go to an LLM, but will be processed in-context by code within greatsun-dev. These commands are:
- `avatar commit`: stages, commits, and pushes current code to all repos with a unified commit message description, and clears the avatar context. (to be built)
- `avatar clear`: clears the avatar context (to be built)

Exit
- `avatar down` exits the avatar back to the shell. Ctrl-C does the same, more forcefully.

## Project
Our project consists of the following top level directories:

## /avatar
Processing queries to LLMs and their results for developer approval and implementation. LLM instructions and management files, as well as logs.

## /central-logs
Folder to be created for compiling and monitoring logs from the projects in credex-ecosystem and from greatsun-dev.

## /credex-ecosystem
The credex-core API and any clients that need to be tested, developed, or employed in research. These repositories are imported directly into this dev environment, and we make commits together across all impacted repos, including this one.

- Currenty under development are:
  - credex-core, our core API on an express.js server.
  - vimbiso-pay, a whatsapp chatbot written in python.

## /data-analysis
Folder to be created for tools to analyze existing data in the credex-ecosystem

## /docs
Documentation for the greatsun-dev environment.

## /simulations
Folder to be created for deploying simulations consisting of patterns of transactions over time for development and research purposes.

## /tests
Folder to be created for unit tests, performance tests, etc

# Getting started
If you've already set your configuration, just type `avatar up` in the terminal to get started

# Developer resources
- To configure your environment, see [Configuration](docs/greatsun-dev_configuration.md)

** This is the credex-core submodule README.md **

File not found: credex-ecosystem/credex-core/README.md

** This is the vimbiso-pay submodule README.md **

File not found: credex-ecosystem/vimbiso-pay/README.md

** This is the current project **

# currentProject.md

Set up the greatsun-dev environment for testing and deploying credex-core and credex-bot as quickly as possible.

** IMPORTANT IMPORTANT IMPORTANT: Current Instructions from Developer: the purpose of this conversation **

summarize /workspaces/greatsun-dev/git_manager.sh and /workspaces/greatsun-dev/start-services.sh and /workspaces/greatsun-dev/start-services.sh for me, and let me know if combining them would be advisable

Reference File: 

No reference file provided.

Full Project Structure:

{
  "docs": {
    "greatsun-dev_configuration.md": null,
    "devEnvNext.md": null
  },
  ".devcontainer": {
    "devcontainer.json": null
  },
  "main.py": null,
  "README.md": null,
  "avatar": {
    "avatarUpCommands.py": null,
    "avatarConversation.txt": null,
    "utils.py": null,
    "currentProject.md": null,
    "avatarOrientation.md": null,
    "avatarUp.py": null,
    "messageFromDeveloper.md": null
  },
  "central-logs": {
    "placeholder.txt": null
  },
  "requirements.txt": null
}

** END avatarUp message **


To provide a summary of the requested files and offer advice on combining them, I'll need to read their contents first. Let me start by reading each file.

Content of /workspaces/greatsun-dev/git_manager.sh:
#!/bin/bash

# Function to execute git commands in a repository
execute_git_command() {
    local repo=$1
    local command=$2
    echo "Executing in $repo: $command"
    if [ "$repo" = "greatsun-dev" ]; then
        eval "$command"
    else
        (cd "$repo" && eval "$command")
    fi
}

# Function to check if a repository has changes
has_changes() {
    local repo=$1
    if [ "$repo" = "greatsun-dev" ]; then
        git status --porcelain | grep -q .
    else
        (cd "$repo" && git status --porcelain | grep -q .)
    fi
}

# Repositories
repos=("vimbiso-pay" "credex-core" "greatsun-dev")

# Function to create new branches
create_branches() {
    local new_branch=$1
    if [ -z "$new_branch" ]; then
        read -p "Enter new branch name: " new_branch
    fi
    for repo in "${repos[@]}"; do
        execute_git_command "$repo" "git fetch --all"
        execute_git_command "$repo" "git checkout -b $new_branch origin/$new_branch || git checkout -b $new_branch"
    done
}

# Function to checkout branches
checkout_branches() {
    read -p "Enter branch name to checkout: " checkout_branch
    for repo in "${repos[@]}"; do
        execute_git_command "$repo" "git checkout $checkout_branch"
    done
}

# Function to push changes
push_changes() {
    read -p "Enter commit message: " commit_message
    uuid=$(uuidgen)
    for repo in "${repos[@]}"; do
        if has_changes "$repo"; then
            execute_git_command "$repo" "git add ."
            execute_git_command "$repo" "git commit -m \"$commit_message [$uuid]\""
            execute_git_command "$repo" "git push origin $(git rev-parse --abbrev-ref HEAD)"
        else
            echo "No changes in $repo"
        fi
    done
}

# Check if script is run on startup
if [ "$1" = "startup" ]; then
    echo "Running on startup. Creating a new branch."
    create_branches "feature-$(date +%Y%m%d-%H%M%S)"
else
    # Main menu
    while true; do
        echo "1. Create new branches"
        echo "2. Checkout branches"
        echo "3. Push changes"
        echo "4. Exit"
        read -p "Choose an option: " choice
        case $choice in
            1) create_branches ;;
            2) checkout_branches ;;
            3) push_changes ;;
            4) exit 0 ;;
            *) echo "Invalid option" ;;
        esac
    done
fi


Content of /workspaces/greatsun-dev/start-services.sh:
#!/bin/bash

# Function to start a service
start_service() {
    local service_name=$1
    local start_command=$2
    local log_file="/workspaces/greatsun-dev/${service_name}.log"

    echo "Starting ${service_name}..."
    if [ -d "/workspaces/greatsun-dev/${service_name}" ]; then
        cd "/workspaces/greatsun-dev/${service_name}"
        eval "${start_command} > ${log_file} 2>&1 &"
    else
        echo "Warning: ${service_name} directory not found. Skipping."
    fi
}

echo "Starting greatsun-dev..."
cd /workspaces/greatsun-dev
python main.py > /workspaces/greatsun-dev/greatsun-dev.log 2>&1 &

echo "Starting credex-core..."
cd /workspaces/greatsun-dev/credex-core
start_service "credex-core" "npm run dev"

echo "Starting vimbiso-pay..."
cd /workspaces/greatsun-dev/vimbiso-pay
source venv/bin/activate
start_service "vimbiso-pay" "python app/manage.py runserver 0.0.0.0:8000"
deactivate

cd /workspaces/greatsun-dev

# Wait for services to start
timeout=60
start_time=$(date +%s)
while true; do
    if grep -q "Starting development server" "/workspaces/greatsun-dev/credex-core.log" && \
       grep -q "Starting development server at http://0.0.0.0:8000/" "/workspaces/greatsun-dev/vimbiso-pay.log" && \
       grep -q "vimbiso-pay is running" "/workspaces/greatsun-dev/greatsun-dev.log"; then
        echo "All services started successfully!"
        break
    fi

    current_time=$(date +%s)
    if [ $((current_time - start_time)) -ge $timeout ]; then
        echo "Timeout: One or more services failed to start within ${timeout} seconds."
        echo "credex-core log:"
        tail -n 20 /workspaces/greatsun-dev/credex-core.log
        echo "vimbiso-pay log:"
        tail -n 20 /workspaces/greatsun-dev/vimbiso-pay.log
        echo "greatsun-dev log:"
        tail -n 20 /workspaces/greatsun-dev/greatsun-dev.log
        exit 1
    fi

    sleep 1
done

# Keep the script running and tail the log files
tail -f /workspaces/greatsun-dev/central-logs/credex-core.log /workspaces/greatsun-dev/central-logs/vimbiso-pay.log /workspaces/greatsun-dev/central-logs/greatsun-dev.log


Content of /workspaces/greatsun-dev/docker-compose.yml:
File not found: /workspaces/greatsun-dev/docker-compose.yml


Based on the content of the files I've read, here's a summary of each script and advice on combining them:

1. git_manager.sh:
This script manages Git operations across multiple repositories (vimbiso-pay, credex-core, and greatsun-dev). It provides functions to:
- Create new branches
- Checkout branches
- Push changes with a unified commit message
- Handle startup operations

The script uses a menu-driven interface for interactive use and can also be run with a "startup" parameter to create a new branch automatically.

2. start-services.sh:
This script is responsible for starting various services in the greatsun-dev environment. It:
- Starts the greatsun-dev main Python script
- Starts the credex-core service (npm run dev)
- Starts the vimbiso-pay service (Django development server)
- Monitors the startup process and logs
- Tails the log files for ongoing monitoring

3. docker-compose.yml:
This file was not found in the specified location.

Advice on combining the scripts:

1. Combining git_manager.sh and start-services.sh could be beneficial for several reasons:
- It would provide a single entry point for managing both Git operations and service startup.
- It could ensure that the correct branches are checked out before starting services.
- It would simplify the overall workflow for developers.

2. Here's a proposed structure for combining the scripts:
- Create a new script called `greatsun-dev-manager.sh`
- Include all functions from both scripts
- Create a main menu that offers options for:
a. Git operations (create branches, checkout, push changes)
b. Start services
c. Stop services (new function to be added)
d. View logs
e. Exit

3. Improvements and additions:
- Add error handling and validation for user inputs
- Implement a configuration file to store repository paths and service commands
- Add a function to stop running services gracefully
- Implement logging for the manager script itself

4. Regarding docker-compose.yml:
- If containerization is planned for this project, creating a docker-compose.yml file would be beneficial.
- It could define services for greatsun-dev, credex-core, and vimbiso-pay, making it easier to manage the entire stack.
- The start-services.sh logic could potentially be replaced by docker-compose up, simplifying service management.

In conclusion, combining the scripts would create a more cohesive and user-friendly management tool for the greatsun-dev environment. It would streamline operations and potentially reduce errors by providing a single interface for both Git and service management.